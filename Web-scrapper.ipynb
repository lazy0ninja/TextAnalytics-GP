{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41384ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup # documentation available at : www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import requests # sends http requests and access the page : docs.python-requests.org/en/latest/\n",
    "import csv # creates the output csv file\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "#import unicodedata # works with string encoding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2664e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "entry = []\n",
    "urlnumber = 1 # Give the page number to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8391ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while urlnumber < 544:  # Set the last page number you want to scrape\n",
    "    url = f'https://forums.edmunds.com/discussion/7526/general/x/midsize-sedans-2-0/p{urlnumber}'\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)  # Sending a request to access the page\n",
    "        r.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    except Exception as e:\n",
    "        print(\"Error message:\", e)\n",
    "        break\n",
    "\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, 'lxml')  # Parsing the page source with lxml parser\n",
    "\n",
    "    for outer_div in soup.find_all('div', class_='Comment'):\n",
    "        entry = []\n",
    "        try:\n",
    "            # Skip entries with embedded media like YouTube videos\n",
    "            if outer_div.find('iframe', src=lambda value: 'youtube' in value if value else False):\n",
    "                continue\n",
    "\n",
    "            # Skip entries with images or other embedded content that is not text\n",
    "            if outer_div.find(['img', 'video', 'embed', 'object']):\n",
    "                continue\n",
    "\n",
    "            # Process the author of the comment\n",
    "            author_info = outer_div.find('a', class_='Username')\n",
    "            if author_info and author_info.string:\n",
    "                entry.append(author_info.string.strip().encode(\"utf-8\"))\n",
    "\n",
    "            # Process the date and time of the comment\n",
    "            time_info = outer_div.find('time')\n",
    "            if time_info and time_info.string:\n",
    "                entry.append(time_info.string.strip().encode('iso-8859-1'))\n",
    "\n",
    "            # Process the main message of the comment\n",
    "            message_div = outer_div.find('div', class_='Message')\n",
    "            if message_div:\n",
    "                # Remove non-text elements like emojis or other media\n",
    "                for non_text in message_div.find_all(['img', 'video', 'embed', 'object']):\n",
    "                    non_text.decompose()\n",
    "                \n",
    "                # Get the text content, replacing line breaks with spaces\n",
    "                text = message_div.get_text(separator=\" \", strip=True)\n",
    "                entry.append(text.encode('ascii', 'replace'))\n",
    "\n",
    "            # If the entry has content, add it to the entries list\n",
    "            if entry:\n",
    "                entries.append(entry)\n",
    "\n",
    "        except Exception as inner_e:\n",
    "            print(\"Error processing a comment:\", inner_e)\n",
    "            continue  # Skip this comment and continue with the next one\n",
    "\n",
    "    urlnumber += 1  # Increment the page number to move to the next page\n",
    "\n",
    "# Output or process your entries list as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedb138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to edmunds_extraction.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert a list of byte to list a of string     \n",
    "stringlist=[[x.decode('iso-8859-1') for x in entry] for entry in entries]\n",
    "# Save the list to a csv file\n",
    "\n",
    "headers = ['date', 'userid', 'message']\n",
    "\n",
    "with open('edmunds_extraction.csv', 'w') as output:\n",
    "    writer = csv.writer(output, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(stringlist)\n",
    "\n",
    "print (\"Wrote to edmunds_extraction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3bcfee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
